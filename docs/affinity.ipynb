{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2abd732d-c9ea-4aee-b037-d04c00e4168b",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    ".. include:: sinebow.rst\n",
    "\n",
    "```\n",
    "{sinebow20}`Affinity segmentation`\n",
    "==================================\n",
    "\n",
    "This is the term that I think best describes encoding an image segmentation it is most general, information-dense form: an affinity graph. To explain what this is, we will first consider two cells in contact. \n",
    "\n",
    "{header-2}`The hierarchy of segmentation encoding`\n",
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c831a-7187-4e23-adbd-9031c30d6b4b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154cffb0-8588-4704-a5b4-a5570306d3df",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Load image and masks\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi'] = 600\n",
    "# mpl.rcParams['facecolor'] = [0]*4\n",
    "\n",
    "plt.rc('figure', facecolor=[0]*4)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "mpl.use('Agg')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from cellpose_omni import io, plot\n",
    "\n",
    "\n",
    "import omnipose\n",
    "omnidir = Path(omnipose.__file__).parent.parent\n",
    "basedir = os.path.join(omnidir,'docs','_static')\n",
    "# name = 'ecoli_phase'\n",
    "name = 'ecoli'\n",
    "ext = '.tif'\n",
    "image = io.imread(os.path.join(basedir,name+ext))\n",
    "masks = io.imread(os.path.join(basedir,name+'_labels'+ext))\n",
    "slc = omnipose.utils.crop_bbox(masks>0,pad=0)[0]\n",
    "masks = masks[slc]\n",
    "image = image[slc]\n",
    "\n",
    "# Plot a few things \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from omnipose.plot import apply_ncolor, plot_edges, imshow\n",
    "from omnipose import utils\n",
    "import numpy as np\n",
    "# import matplotlib_inline\n",
    "# matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "\n",
    "images = [image, masks>0, apply_ncolor(masks), masks>0] \n",
    "labels = ['Image\\n(phase contrast)', 'Semantic\\nsegmentation', \n",
    "          'Instance\\nsegmentation', 'Affinity\\nsegmentation']  \n",
    "\n",
    "# Set up the figure and subplots\n",
    "N = len(images)\n",
    "\n",
    "f = 1\n",
    "dpi = mpl.rcParams['figure.dpi']\n",
    "Y,X = masks.shape[-2:]\n",
    "szX = max(X//dpi,2)*f\n",
    "szY = max(Y//dpi,2)*f\n",
    "M = 1\n",
    "fig, axes = plt.subplots(M, N, figsize=(szX*N,szY*M))  \n",
    "\n",
    "# Iterate over each subplot and set the image, label, and formatting\n",
    "c =  [0.5]*3\n",
    "fontsize = 8\n",
    "\n",
    "# bounds = [40,20,10,10]\n",
    "bounds = [11,22,8,8]\n",
    "\n",
    "sy,sx,wy,wx = bounds\n",
    "zoomslc = tuple([slice(sy,sy+wy),slice(sx,sx+wx)])\n",
    "h,w = masks.shape\n",
    "# extent = [0,w,0,h]\n",
    "extent = np.array([0,w,0,h])#-0.5\n",
    "# extent2 = np.array([0,w,h,0])-0.5 # for upper\n",
    "extent2 = extent\n",
    "\n",
    "cmap='inferno'\n",
    "\n",
    "zoom = 3\n",
    "color = [.75]*3\n",
    "edgecol = [1/3]*3\n",
    "edgecol = [.75]*3+[.5]\n",
    "# edgecol = [.5,.75,0]+[2/3]\n",
    "\n",
    "lw= .2\n",
    "labelpad = 3\n",
    "fontsize2 = fontsize/1.25\n",
    "for i, ax in enumerate(axes):\n",
    "\n",
    "    # inset axes\n",
    "    axins = zoomed_inset_axes(ax, zoom, loc='lower left',\n",
    "                              bbox_to_anchor=(-wx/w,-2*wy/h), \n",
    "                              bbox_transform=ax.transAxes)\n",
    "    \n",
    "    if i==N-1:\n",
    "        # ax.invert_yaxis()\n",
    "        \n",
    "        dim = masks.ndim\n",
    "        shape = masks.shape\n",
    "        steps, inds, idx, fact, sign = utils.kernel_setup(dim)\n",
    "        coords = np.nonzero(masks) \n",
    "        affinity_graph = omnipose.core.masks_to_affinity(masks, coords, steps, \n",
    "                                                         inds, idx, fact, sign, dim)\n",
    "        neighbors = utils.get_neighbors(coords,steps,dim,shape)\n",
    "        summed_affinity, affinity_cmap = plot_edges(shape,affinity_graph,neighbors,coords,\n",
    "                                                    figsize=1,fig=fig,ax=ax,extent=extent2,\n",
    "                                                    edgecol=edgecol,cmap=cmap,linewidth=lw\n",
    "                                                   )\n",
    "  \n",
    "        \n",
    "        axins.invert_yaxis()\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "        summed_affinity, affinity_cmap = plot_edges(shape,affinity_graph,neighbors,coords,\n",
    "                                            figsize=1,fig=fig,ax=axins,\n",
    "                                            extent=extent2,\n",
    "                                            edgecol=edgecol,linewidth=lw*zoom,cmap=cmap\n",
    "                                           )\n",
    "\n",
    "        axins.set_xlim(zoomslc[1].start, zoomslc[1].stop)\n",
    "        axins.set_ylim(h-zoomslc[0].start, h-zoomslc[0].stop)\n",
    "        \n",
    "\n",
    "        loc1,loc2 = 4,2\n",
    "        patch, pp1, pp2 = mark_inset(ax, axins, loc1=loc1, loc2=loc2, fc=\"none\", ec=color+[1],zorder=2)\n",
    "        pp1.loc1 = 4\n",
    "        pp1.loc2 = 1\n",
    "        pp2.loc1 = 2\n",
    "        pp2.loc2 = 3\n",
    "        \n",
    "        \n",
    "        N = affinity_cmap.N\n",
    "        colors = affinity_cmap.colors\n",
    "  \n",
    "        cax = inset_axes(ax, width=\"50%\", height=\"100%\", loc='lower right',\n",
    "                 bbox_to_anchor=(-.05, -0.7, 1, 1), bbox_transform=ax.transAxes,\n",
    "                 borderpad=0)\n",
    "\n",
    "        # Display the color swatches as an image\n",
    "        n = np.arange(3,9)\n",
    "        Nc = len(n)\n",
    "        cax.imshow(affinity_cmap(n.reshape(1,Nc)))#,vmin=n[0]-1,vmax=n[-1]+1)\n",
    "\n",
    "        # Set the y ticks and tick labels\n",
    "        cax.set_xticks(np.arange(Nc))\n",
    "        nums = [str(i) for i in n]\n",
    "        cax.set_xticklabels(nums,c=c,fontsize=fontsize2)\n",
    "        cax.tick_params(axis='both', which='both', length=0, pad=labelpad)\n",
    "        cax.set_yticks([])\n",
    "        \n",
    "        cax.set_aspect(ha/wa)\n",
    "        cax.set_title('Connections',c=c,fontsize=fontsize2,pad=labelpad)\n",
    "        for spine in cax.spines.values():\n",
    "            spine.set_color(None)\n",
    "    else:\n",
    "        \n",
    "        ax.imshow(images[i],cmap='gray',extent=extent)\n",
    "        # axins.imshow(images[i][zoomslc],extent=extent,origin='upper')\n",
    "        axins.imshow(images[i],extent=extent,cmap='gray')\n",
    "        # axins.imshow(images[i])#,extent=extent)\n",
    "        axins.set_xlim(zoomslc[1].start, zoomslc[1].stop)\n",
    "        axins.set_ylim(zoomslc[0].start, zoomslc[0].stop)\n",
    "     \n",
    "        mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=color+[1],zorder=2)\n",
    "\n",
    "\n",
    "\n",
    "    ax.set_title(labels[i],c=c,fontsize=fontsize,fontweight=\"bold\",pad=5)\n",
    "    ax.axis('off')  \n",
    "    axins.set_xticks([])\n",
    "    axins.set_yticks([])\n",
    "    axins.set_facecolor([0]*4)\n",
    "\n",
    "    for spine in axins.spines.values():\n",
    "        spine.set_color(color)\n",
    "\n",
    "        \n",
    "plt.subplots_adjust(wspace=0.15)\n",
    "fig.patch.set_facecolor([0]*4)    \n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec61b46-fcb8-4e95-acaa-0135a1876d1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Semantic segmentation sorts pixels into semantic classes. This is often just two classes, or binary classification: foreground and background. In this case, foreground is cell and background is media. As you can see, semantic segmentation does not discern between adjacent instances of foreground objects. We store a semantic segmentation as a binary image file with the same dimensions as the image itself, with foreground pixels labeled {py}`True` ({py}`1`) and background {py}`False` ({py}`0`). \n",
    "\n",
    "Instance segmentation assigns a unique integer to the pixels each instance of an object - in this case, each cell. This is also conveniently stored as an image file, typically uint8 (unsigned 8-bit integer) for up to $2^{8}-1=255$ labels or uint16 (unsigned 16-bit integer) for up to $2^{16}-1=65535$ labels. Signed and/or unsigned 32- or 64-bit formats may also be used, but your OS may not be able to preview these files in its native file manager. \n",
    "\n",
    "```{note}\n",
    "Some instance labels use -1 as an \"ignore\" label. This can be in conflict with several tasks from indexing to label formatting, which assume unsigned integers, so care must be taken when working with signed formats (int) versus unsigned (uint). \n",
    "```\n",
    "\n",
    "\n",
    "{header-2}`Bad labels I: Semantic islands to instance labels`\n",
    "-------------------------------------------------------------\n",
    "Semantic segmentation can be converted into instance segmentation, and this forms the basis of many instance segmentation pipelines. The general steps are:\n",
    "1. Pre-process image: traditional filtering/blurring/feature extraction or DNN transformation \n",
    "2. Threshold processed image: adaptive techniques are usually used on the pre-processed image to ensure that the majority of objects pixels are identified despite variations within an image and among images in a dataset. Importantly, object boundaries **must not be identified** as foreground. This allows each object to be associated with a unique island of foreground pixels. \n",
    "3. These unique blobs are identified using **connected components labeling**. This is the process of building an affinity graph, where pixels are nodes and edges are formed between any adjacent foreground pixels. Adjacency can be defined most narrowly by sharing edges (1-connected in Python, 4-connected in MATLAB) or more broadly by sharing either edges or vertices (2-connected in Python, 8-connected in MATLAB). The graph is then traversed to find all connected components of the graph. \n",
    "\n",
    "These points are illustrated below. By simulating the amount of foreground pixels detected by filtering+thresholding, we see that is is impossible to distinguish between the two cells until much of the boundary is lost, particularly when using 2-connectivity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d294b1-09f4-462e-a610-e0b0f7e10093",
   "metadata": {
    "editable": true,
    "mystnb": {
     "image": {
      "align": "center",
      "width": "75%"
     }
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import skimage.measure\n",
    "\n",
    "connectivity = [1,2]\n",
    "cutoffs = [4,5,6]\n",
    "row_labels = ['{}-connected'.format(i) for i in connectivity]\n",
    "col_labels = ['cutoff = {}'.format(i) for i in cutoffs]\n",
    "# Define the grid dimensions\n",
    "num_rows = len(row_labels)\n",
    "num_cols = len(col_labels)\n",
    "\n",
    "# Create the grid of subplots\n",
    "\n",
    "f = .75\n",
    "dpi = mpl.rcParams['figure.dpi']\n",
    "Y,X = masks.shape[-2:]\n",
    "szX = max(X//dpi,2)*f\n",
    "szY = max(Y//dpi,2)*f\n",
    "fig, axes = plt.subplots(num_rows, num_cols,figsize=(szX*num_cols,szY*num_rows),facecolor=[0]*4)\n",
    "color = [0.5]*3\n",
    "for row,conn in enumerate(connectivity):\n",
    "    for col,cutoff in enumerate(cutoffs):\n",
    "        bin0 = summed_affinity>cutoff\n",
    "        msk0 = skimage.measure.label(bin0,connectivity=conn)\n",
    "        pic = apply_ncolor(msk0)\n",
    "        \n",
    "        \n",
    "        dim = masks.ndim\n",
    "        shape = masks.shape\n",
    "        steps, inds, idx, fact, sign = utils.kernel_setup(dim)\n",
    "        coords = np.nonzero(msk0) \n",
    "        affinity_graph = omnipose.core.masks_to_affinity(msk0, coords, steps, \n",
    "                                                         inds, idx, fact, sign, dim)\n",
    "        neighbors = utils.get_neighbors(coords,steps,dim,shape)\n",
    "        \n",
    "        #choose to plot cardinal connections only\n",
    "        step_inds = None if conn==2 else inds[1]\n",
    "        \n",
    "        \n",
    "        ax = axes[row,col]\n",
    "        ax.axis('off')\n",
    "        \n",
    "        plot_edges(shape,affinity_graph,neighbors,coords,figsize=1,extent=extent,\n",
    "                   fig=fig,ax=ax,step_inds=step_inds,pic=pic,origin='lower',edgecol=[1,1,1,0.5])\n",
    "    \n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        \n",
    "# Add column labels along the top\n",
    "for ax, column_label in zip(axes[0], col_labels):\n",
    "    ax.annotate(column_label, xy=(0.5, 1), xytext=(0, ax.xaxis.labelpad),\n",
    "                xycoords=ax.xaxis.label, textcoords='offset points',\n",
    "                ha='center', va='baseline',color=color,fontsize=fontsize)\n",
    "\n",
    "# Add row labels on the left side\n",
    "for ax, row_label in zip(axes[:, 0], row_labels):\n",
    "    ax.annotate(row_label, xy=(0, 0), xytext=(-ax.yaxis.labelpad + 20, 0),\n",
    "                xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                ha='right', va='center', rotation=90,color=color,fontsize=fontsize)\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95, wspace=0.0, hspace=0.0)\n",
    "# fig.patch.set_facecolor([0]*4)    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c4a19-fe78-4c0e-bee3-5ac2b3efd6ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "Although such sloppy segmentation is good enough for some tasks, we have a better tools now. So in general, do not use image thresholding for segmentation. \n",
    "\n",
    "\n",
    "{header-2}`Bad labels II: Watershed lines`\n",
    "------------------------------------------\n",
    "While we are on the topic, missing boundary pixels also frequently arise when applying the watershed transform. As usually implemented, this ubiquitous operation returns a semantic classification of an image into watershed lines and catchment basins. As you can tell by the above example, this means that distinct basins must be separated by a 1- or 2-connected watershed line, and therefore boundary pixels are always left unclassified. \n",
    "\n",
    "There are implementations that allow users to return instance labels *without* the gaps let by watershed lines (*e.g.*, `skimage.segmentation.watershed`), but I have yet to see a paper published using this method. Despite this fix, watershed also tends to over-segment images (even when transformed by traditional filters or DNNs). So in general, do not use watershed for instance segmentation. \n",
    "\n",
    "\n",
    "{header-2}`Bad labels III: Self-contact boundaries`\n",
    "---------------------------------------------------\n",
    "Instance labels are good enough to fully describe a lot of objects. More precisely, there is a bijective map between the affinity graph and the instance label matrix whenever all edge pixels are in contact with a non-self pixel. This assumption fails in many interesting (and biologically relevant) scenarios, including bacterial microscopy. Consider the following image containing one extremely filamentous cell and corresponding cell mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87756e76-4b41-48a7-b6c3-06ea4449690c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# read in files; this is an entire movie, but we will just be looking at the last frame \n",
    "import tifffile\n",
    "\n",
    "nm = 'long_10_2'\n",
    "masks = tifffile.imread(os.path.join(basedir,nm+'_op_masks.tif'))\n",
    "phase = tifffile.imread(os.path.join(basedir,nm+'_phase.tif'))\n",
    "fluor = tifffile.imread(os.path.join(basedir,nm+'_fluor.tif'))\n",
    "afnty = utils.load_nested_list(os.path.join(basedir,nm+'_affinity.npz'))\n",
    "\n",
    "# make figure\n",
    "import omnipose, cellpose_omni\n",
    "im = phase[-1]\n",
    "msk = masks[-1]\n",
    "\n",
    "f = 1\n",
    "c = [0.5]*3\n",
    "fontsize=7\n",
    "dpi = mpl.rcParams['figure.dpi']\n",
    "Y,X = im.shape[-2:]\n",
    "szX = max(X//dpi,2)*f\n",
    "szY = max(Y//dpi,2)*f\n",
    "\n",
    "titles = [r'$\\bf{image}$'+'\\n(phase contrast)', r'$\\bf{label}$'+'\\n(single cell mask)', r'$\\bf{boundary}$'+'\\n(from cell mask)']\n",
    "ol = cellpose_omni.utils.masks_to_outlines(msk,omni=True)\n",
    "# outlines = np.stack([ol]*4,axis=-1)*0.5\n",
    "images = [im,\n",
    "          omnipose.plot.apply_ncolor(msk),\n",
    "          omnipose.plot.apply_ncolor(ol,offset=.5)]\n",
    "\n",
    "N = len(images)\n",
    "fig, axes = plt.subplots(1,3, figsize=(szX*N,szY))  \n",
    "fig.patch.set_facecolor([0]*4)\n",
    "\n",
    "h,w = im.shape\n",
    "extent = np.array([0,w,0,h])#-0.5\n",
    "sy,sx,wy,wx = [h//2.5,w//3.6,40,40]\n",
    "zoomslc = tuple([slice(sy,sy+wy),slice(sx,sx+wx)])\n",
    "zoom = 5\n",
    "asp = h/w\n",
    "\n",
    "lwa = 2/N # linewidth for axes\n",
    "lw = lwa/20 # linewidth for affinity graph\n",
    "labelpad = 2\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    \n",
    "    # inset axes....\n",
    "    # axins = ax.inset_axes([0.5, 0.5, 0.47, 0.47])\n",
    "    # axins = inset_axes(ax, 1,1 , loc=2, bbox_to_anchor=(.08, 0.35))\n",
    "    axins = zoomed_inset_axes(ax, zoom, loc='lower left',\n",
    "                              # bbox_to_anchor=(1.1, 1.1), \n",
    "                              # bbox_to_anchor=(-.15,-.15), \n",
    "                              bbox_to_anchor=(-(wx/w)*zoom/(1.25),-zoom/1.5*wy/h), \n",
    "                              bbox_transform=ax.transAxes)\n",
    "\n",
    "\n",
    "   \n",
    "    ax.imshow(images[i],cmap='gray',extent=extent)\n",
    "    # axins.imshow(images[i][zoomslc],extent=extent,origin='upper')\n",
    "    axins.imshow(images[i],extent=extent,cmap='gray')\n",
    "    # axins.imshow(images[i])#,extent=extent)\n",
    "    axins.set_xlim(zoomslc[1].start, zoomslc[1].stop)\n",
    "    axins.set_ylim(zoomslc[0].start, zoomslc[0].stop)\n",
    "\n",
    "    mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=color+[1], zorder=2, lw=lwa)\n",
    "\n",
    "    ax.set_title(titles[i],c=c,fontsize=fontsize,pad=5)\n",
    "    ax.axis('off')  \n",
    "    # axins.axis('off')  \n",
    "    axins.set_xticks([])\n",
    "    axins.set_yticks([])\n",
    "    axins.set_facecolor([0]*4)\n",
    "\n",
    "    \n",
    "    for spine in axins.spines.values():\n",
    "        spine.set_color(color)\n",
    "        spine.set_linewidth(lwa)\n",
    "\n",
    "        \n",
    "plt.subplots_adjust(wspace=0,hspace=0)\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ddcf06-b8f7-467d-b712-4c8574e18f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Because the label for this cell is the same integer on either side of a self-contact interface, we cannot localize the boundary of the cell at these interfaces. However, affinity segmentation encodes not only the information necessary to recontruct cell boundaries but also to traverse cell boundarues as a parametric contour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff5ec1-f385-4210-b66e-d3707f06f9ca",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import omnipose, cellpose_omni\n",
    "from scipy import signal\n",
    "t = -1 # last frame\n",
    "im = phase[t]\n",
    "msk = masks[t]\n",
    "\n",
    "f = 1\n",
    "c = [0.5]*3\n",
    "fontsize = 4\n",
    "dpi = mpl.rcParams['figure.dpi']\n",
    "Y,X = im.shape[-2:]\n",
    "szX = max(X//dpi,2)*f\n",
    "szY = max(Y//dpi,2)*f\n",
    "\n",
    "\n",
    "\n",
    "titles = [r'$\\bf{image}$'+'\\n(phase contrast)', \n",
    "          r'$\\bf{connectivity}$'+'\\n(affinity graph)', \n",
    "          r'$\\bf{boundary}$'+'\\n(from affinity graph)',\n",
    "          r'$\\bf{contour}$'+'\\n(traced with affinity)']\n",
    "\n",
    "# extract the addinity graph and coordinate array \n",
    "aa = afnty[t]\n",
    "shape = msk.shape\n",
    "dim = msk.ndim\n",
    "neighbors = aa[:dim]\n",
    "affinity_graph = aa[dim]#.astype(bool) #VERY important to cast to bool, now done internally \n",
    "idx = affinity_graph.shape[0]//2\n",
    "coords = tuple(neighbors[:,idx])\n",
    "\n",
    "# make the boundary\n",
    "ol = omnipose.core.affinity_to_boundary(msk,affinity_graph,coords)\n",
    "\n",
    "# make the contour\n",
    "contour_map, contour_list = omnipose.core.get_contour(msk,affinity_graph,coords,cardinal_only=1)\n",
    "\n",
    "cmap='inferno'\n",
    "color = [0.5]*3\n",
    "\n",
    "\n",
    "\n",
    "# contour_colored = np.stack([(contour_map>1).astype(np.float32)]*4,axis=-1)\n",
    "contour_colored = np.zeros(contour_map.shape+(4,))\n",
    "\n",
    "for contour in contour_list:\n",
    "    # coords_t = np.unravel_index(contour,contour_map.shape)\n",
    "    coords_t = np.stack([c[contour] for c in coords])\n",
    "    cyclic_diff = np.diff(np.append(coords_t, coords_t[:, 0:1], axis=1), axis=1)\n",
    "\n",
    "    a = cyclic_diff\n",
    "    window_size = 11\n",
    "    window = np.ones(window_size) / window_size\n",
    "    cyclic_diff = signal.convolve2d(np.concatenate((a[:, -window_size+1:], a, a[:, :window_size-1]), axis=1), np.expand_dims(window, axis=0), mode='same')[:, window_size-1:-window_size+1]\n",
    "\n",
    "    angles = np.arctan2(cyclic_diff[1], cyclic_diff[0])+np.pi\n",
    "\n",
    "\n",
    "    a = 2\n",
    "    r = ((np.cos(angles)+1)/a)\n",
    "    g = ((np.cos(angles+2*np.pi/3)+1)/a)\n",
    "    b =((np.cos(angles+4*np.pi/3)+1)/a)\n",
    "    \n",
    "    rgb = np.stack((r,g,b,np.ones_like(angles)),axis=-1)\n",
    "    \n",
    "    # v = np.array(range(len(contour)))/len(contour)\n",
    "    # contour_colored[tuple(coords_t)] = ctr_cmap(v)\n",
    "    contour_colored[tuple(coords_t)] = rgb\n",
    "\n",
    "\n",
    "images = [im,\n",
    "          None,\n",
    "          omnipose.plot.apply_ncolor(ol,offset=.5),\n",
    "          contour_colored]\n",
    "\n",
    "N = len(images)\n",
    "A = N//2\n",
    "B = N-A\n",
    "fig, axes = plt.subplots(2,B, figsize=(szX*A,szY*B))  \n",
    "fig.patch.set_facecolor([0]*4)\n",
    "\n",
    "h,w = im.shape\n",
    "extent = np.array([0,w,0,h])#-0.5\n",
    "sy,sx,wy,wx = [h//2.5,w//3.6,40,40]\n",
    "zoomslc = tuple([slice(sy,sy+wy),slice(sx,sx+wx)])\n",
    "zoom = 5\n",
    "asp = h/w\n",
    "\n",
    "lwa = 2/N # linewidth for axes\n",
    "lw = lwa/20 # linewidth for affinity graph\n",
    "labelpad = 4/3\n",
    "\n",
    "fontsize2 = fontsize/1.1\n",
    "\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    \n",
    "    # inset axes....\n",
    "    # axins = ax.inset_axes([0.5, 0.5, 0.47, 0.47])\n",
    "    # axins = inset_axes(ax, 1,1 , loc=2, bbox_to_anchor=(.08, 0.35))\n",
    "    axins = zoomed_inset_axes(ax, zoom, loc='lower left',\n",
    "                              # bbox_to_anchor=(1.1, 1.1), \n",
    "                              # bbox_to_anchor=(-.15,-.15), \n",
    "                              bbox_to_anchor=(-(wx/w)*zoom/(1.25),-zoom/1.5*wy/h), \n",
    "                              bbox_transform=ax.transAxes)\n",
    "\n",
    "    if i==1:\n",
    "        # ax.invert_yaxis()\n",
    "        neighbors = utils.get_neighbors(coords,steps,dim,shape)\n",
    "        \n",
    "        # plot the while affinity graph\n",
    "        summed_affinity, affinity_cmap = plot_edges(shape,affinity_graph,neighbors,coords,\n",
    "                                                    figsize=1,fig=fig,ax=ax,extent=extent,\n",
    "                                                    edgecol=edgecol,cmap=cmap,linewidth=lw\n",
    "\n",
    "                                                   )\n",
    "  \n",
    "        # plot the inset one \n",
    "        axins.invert_yaxis()\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "        summed_affinity, affinity_cmap = plot_edges(shape,affinity_graph,neighbors,coords,\n",
    "                                            figsize=1,fig=fig,ax=axins,\n",
    "                                            extent=extent,\n",
    "                                            edgecol=edgecol,linewidth=lw*zoom,cmap=cmap\n",
    "                                           )\n",
    "\n",
    "        # axins.set_xlim(zoomslc[1].start, zoomslc[1].stop)\n",
    "        axins.set_xlim(zoomslc[1].start, zoomslc[1].stop)\n",
    "        \n",
    "        # axins.set_ylim(zoomslc[0].stop, zoomslc[0].start)\n",
    "        # axins.set_ylim(h-zoomslc[0].stop, h-zoomslc[0].start)\n",
    "        axins.set_ylim(h-zoomslc[0].start, h-zoomslc[0].stop)\n",
    "        \n",
    "\n",
    "        loc1,loc2 = 4,2\n",
    "        patch, pp1, pp2 = mark_inset(ax, axins, loc1=loc1, loc2=loc2, fc=\"none\", \n",
    "                                     ec=color+[1],zorder=2,lw=lwa)\n",
    "        pp1.loc1 = 4\n",
    "        pp1.loc2 = 1\n",
    "        pp2.loc1 = 2\n",
    "        pp2.loc2 = 3\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        # Display the color swatches as an image\n",
    "        Nc = affinity_cmap.N\n",
    "        colors = affinity_cmap.colors\n",
    "  \n",
    "        wa = .07\n",
    "        ha = .05\n",
    "        # cax = fig.add_axes([.3975, -.08, wa, ha])\n",
    "        cax = inset_axes(ax, width=\"60%\", height=\"100%\", loc='lower right',\n",
    "                 bbox_to_anchor=(0, -0.7, 1, 1), bbox_transform=ax.transAxes,\n",
    "                 borderpad=0)\n",
    "        \n",
    "        n = np.arange(3,9)\n",
    "        Nc = len(n)\n",
    "        cax.imshow(affinity_cmap(n.reshape(1,Nc)))#,vmin=n[0]-1,vmax=n[-1]+1)\n",
    "\n",
    "        # Set the y ticks and tick labels\n",
    "        # cax.set_yticks(np.arange(N))\n",
    "        cax.set_xticks(np.arange(Nc))\n",
    "        \n",
    "        nums = [str(i) for i in n]\n",
    "        cax.set_xticklabels(nums,c=c,fontsize=fontsize2)\n",
    "        cax.tick_params(axis='both', which='both', length=0, pad=labelpad)\n",
    "        cax.set_yticks([])\n",
    "        \n",
    "        cax.set_aspect(ha/wa)\n",
    "        cax.set_title('Connections',c=c,fontsize=fontsize2, pad=labelpad)\n",
    "        for spine in cax.spines.values():\n",
    "            spine.set_color(None)\n",
    "            \n",
    "        # cax.xaxis.set_labelpad  = -10\n",
    "    else:\n",
    "\n",
    "\n",
    "\n",
    "        ax.imshow(images[i],cmap='gray',extent=extent)\n",
    "        # axins.imshow(images[i][zoomslc],extent=extent,origin='upper')\n",
    "        axins.imshow(images[i],extent=extent,cmap='gray')\n",
    "        # axins.imshow(images[i])#,extent=extent)\n",
    "        axins.set_xlim(zoomslc[1].start, zoomslc[1].stop)\n",
    "        axins.set_ylim(zoomslc[0].start, zoomslc[0].stop)\n",
    "\n",
    "        mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", \n",
    "                   ec=color+[1], zorder=2, lw=lwa)\n",
    "        \n",
    "        \n",
    "        \n",
    "    if i==3:\n",
    "        # ax2 = fig.add_axes([.7, -.15, .25, .25])\n",
    "        ax2 = inset_axes(ax, width=\"60%\", height=\"100%\", loc='lower right',\n",
    "             bbox_to_anchor=(0, -0.7, 1, 1), bbox_transform=ax.transAxes,\n",
    "             borderpad=0)\n",
    "        lw2 = 1\n",
    "\n",
    "        # Create the circle and arrows on the second subplot\n",
    "        circle = plt.Circle((0, 0), 1, fill=False, edgecolor=c,lw=lw2)\n",
    "        ax2.add_artist(circle)\n",
    "\n",
    "        # Set the number of arrows and colormap\n",
    "        n_arrows = 11\n",
    "        cmap = plt.get_cmap('hsv')\n",
    "\n",
    "        for j in range(n_arrows):\n",
    "            angle = j * 2 * np.pi / n_arrows\n",
    "            a = 2\n",
    "            r = ((np.cos(angle)+1)/a)\n",
    "            g = ((np.cos(angle+2*np.pi/3)+1)/a)\n",
    "            b =((np.cos(angle+4*np.pi/3)+1)/a)\n",
    "\n",
    "            rgb = np.stack((r,g,b,np.ones_like(angle)),axis=-1)\n",
    "\n",
    "            \n",
    "            x, y = np.cos(angle), np.sin(angle)\n",
    "            # dx, dy = -y, x\n",
    "            dx, dy = y,-x\n",
    "            \n",
    "            # clr = cmap(j / n_arrows)\n",
    "            ax2.quiver(x, y, dx, dy, color=rgb, angles='xy', scale_units='xy', scale=2, width=.05)\n",
    "\n",
    "        # Add text to the center of the circle\n",
    "        ax2.text(0, 0, 'Angle', ha='center', va='center',c=c,fontsize=fontsize2)\n",
    "\n",
    "        # Set the axis limits and aspect ratio\n",
    "        ax2.set_xlim(-1.5, 1.5)\n",
    "        ax2.set_ylim(-1.5, 1.5)\n",
    "        ax2.set_aspect('equal')\n",
    "\n",
    "        # Remove the axes from the second subplot\n",
    "        ax2.axis('off')\n",
    "\n",
    "    ax.set_title(titles[i],c=c,fontsize=fontsize,pad=3)\n",
    "    ax.axis('off')  \n",
    "    # axins.axis('off')  \n",
    "    axins.set_xticks([])\n",
    "    axins.set_yticks([])\n",
    "    axins.set_facecolor([0]*4)\n",
    "\n",
    "    \n",
    "    for spine in axins.spines.values():\n",
    "        spine.set_color(color)\n",
    "        spine.set_linewidth(lwa)\n",
    "\n",
    "        \n",
    "# plt.subplots_adjust(wspace=-0,hspace=0)\n",
    "plt.subplots_adjust(wspace=-.35,hspace=.5)\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb675242-7785-4867-a3a5-2874b509fa6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Pixels (or in ND, hypervoxels) may be classified as interior or boundary by their net connectivity. An ND hypervoxel connected to all $3^{N}-1$ neighbors is classified as **internal** (8 in 2D, fully 2-connected to both cardinal and ordinal neighbors). Hypervoxels with fewer than $3^{N}-1$ connections are classified as **boundary**. In Omnipose, hypervoxels with fewer than N connections are pruned when using affinity segmentation to avoid spurs and allow cell contours in 2D to be traced. \n",
    "\n",
    "Because connections in an affinity graph are symmetrical, interfaces between objects are 2 hypervoxels thick. That is, the shortest path between the interiors of any two objects will pass through at least two boundary hypervoxels, one belonging to each object. Thresholding-based methods of boundary detection do not guarantee this symmetry and thus predict too many or too few boundary hypervoxels. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
